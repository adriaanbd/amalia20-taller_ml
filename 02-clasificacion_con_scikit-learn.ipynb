{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creando modelos de clasificación con scikit-learn\n",
    "\n",
    "Créditos: Material presentado en este notebook está basado en el curso del [Data School](http://www.dataschool.io/) \"Machine Learning with Text in Python\", cuyos videos están disponibles en [YouTube](https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A) y los notebooks en [GitHub](https://github.com/justmarkham/scikit-learn-videos).\n",
    "\n",
    "**Nota:** Este notebook utiliza Python 3.x and scikit-learn 0.2x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Objetivo\n",
    "\n",
    "- Implementaremos varios modelos de ML para clasificar plantas de la familia Iris en una de tres especies, usando la longitud y ancho de sus pétalos y sépalos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Agenda\n",
    "\n",
    "- ¿Qué es el dataset Iris y cómo se puede utilizar para hacer machine learning (ML)?\n",
    "- ¿Cómo se puede cargar el dataset Iris con scikit-learn?\n",
    "- ¿Cómo se describe un dataset usando la terminologia de ML?\n",
    "- ¿Cuál son los cuatro principales requisitos de scikit-learn para trabajar con datos?\n",
    "- ¿Cómo funciona el algoritmo **K-nearest neighbors** para crear modelos de prediccion?\n",
    "- ¿Cuáles son los cuatro pasos para realizar el **entrenamiento y prediccion de modelos** con scikit-learn?\n",
    "- ¿Cómo puedo aplicar este proceso con **otros modelos de machine learning**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducción al dataset iris\n",
    "\n",
    "Para construir los modelos, utilizaremos el [conjunto de datos flor Iris](https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris), el cual es un conjunto clásico en la comunidad de ML por ser sencillo y útil para explicar los resultados obtenidos de los modelos.\n",
    "\n",
    "En el conjunto a utilizar, las muestras de flor Iris caen dentro de tres especies: Iris setosa, Iris versicolor, y Iris virgínica. En principio, las tres especies pueden lucir muy parecidas entre sí, especialmente entre las dos últimas especies (versicolor y virginica). Sin embargo, y gracias a las cuidadosas mediciones de los investigadores Anderson y Fisher, una muestra puede ser clasificada con un alto grado de precisión por medio de modelos de ML.\n",
    "\n",
    "![Iris](img/iris.png)\n",
    "\n",
    "El conjunto de datos Iris consiste \n",
    "- 50 muestras de 3 especies distintas de iris (150 muestras en total). Los iris también son conocido comunmente como lirios.\n",
    "- Medidas: longitud del sépalo, ancho del sépalo, longitud del pétalo, ancho del pétalo\n",
    "- Iris es un género de plantas rizomatosas de la familia Iridaceae. El mayor género de la familia con más de 300 especies, además de muchos híbridos y cultivares. Además del nombre del género, iris se usa comúnmente para referirse a todas las especies, así como a otros varios géneros estrechamente emparentados y a una subdivisión dentro del género. Fuente: [Wikipedia](https://es.wikipedia.org/wiki/Iris_(planta))\n",
    "\n",
    "\n",
    "| Setosa | Versicolor | Virginica |\n",
    "| :-: | :-: | :-: |\n",
    "| <img src=\"img/iris_setosa.jpg\" width=\"200\"/> | <img src=\"img/iris_versicolor.jpg\" width=\"200\"/> | <img src=\"img/iris_virginica.jpg\" width=\"200\"/> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cargando el dataset iris con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# importa la función load_iris del módulo datasets\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# guarda el objeto tipo \"bunch\", que contiene el dataset iris y sus atributos\n",
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "# imprime la data the iris data\n",
    "# encontrarás 150 muestras o filas, cada una con cuatro valores\n",
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# si sólo quieres ver el principio del conjunto de datos (usualmente eso es suficiente para tener una idea)\n",
    "# por ejemplo, para ver las primeras diez filas\n",
    "iris.data[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b>Pregunta:</b> ¿Qué tipo de objeto es `iris.data`? Escribe el comando en la celda de abajo. Para una guía de que comando usar, revisa en las celdas de arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b>Pregunta:</b> ¿Cómo muestras las cinco primeras filas del conjunto de datos `iris.data`? \n",
    "\n",
    "Para encontrar la respuesta puedes usar las siguientes referencias:\n",
    "- NumPy: the absolute basics for beginners. Indexing and slicing. https://numpy.org/doc/stable/user/absolute_beginners.html#indexing-and-slicing\n",
    "- Cálculo numérico con Numpy. http://research.iac.es/sieinvens/python-course/numpy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b>Pregunta:</b> ¿Cómo muestras los últimos diez valores de la tercera columna del conjunto de datos `iris.data`? \n",
    "\n",
    "Puedes usar las mismas referencias de arriba para encontrar la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# imprime los nombres de las cuatro características\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Pregunta:** ¿Puedes explicar por que cada fila del dataset tiene cuatro valores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# imprime los números enteros que representan las distintas especies de cada observación\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Pregunta:** ¿Cuántas especies distintas posee el dataset iris?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficando el dataset con matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usemos la libreria [Matplotlib](https://matplotlib.org/users/index.html) para graficar el conjunto de datos Iris. Esto es parte del análisis exploratorio de datos que todo analista debe realizar. Mientras mejor conozcas los datos, mejores resultados obtendrás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero importamos la librería para poder usarla\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# los datos tienen cuatro dimensiones (características) asi que no podemos graficar\n",
    "# todos los datos. Seleccionamos dos (al azar) para ver como nos va.\n",
    "x_index = 0\n",
    "y_index = 1\n",
    "\n",
    "# este objeto etiquetará la barra de color con los nombres correctos de las clases\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "# utilizamos la gráfica de tipo `scatter`\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index],\n",
    "            c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3))\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.clim(-0.5, 2.5)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Ejercicio:** Cambia los valores de `x_index` y `y_index` en la celda de arriba y encuentra una combinación de dos parámetros que maximizan la separación de las tres clases. Si lo encuentras, estarías haciendo **reducción de dimensiones**, aunque de forma manual. `Scikit-learn` ofrece tambien algoritmos para realizar esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del dataset iris\n",
    "\n",
    "- 150 **observaciones**\n",
    "- 4 **características** (longitud del sépalo, ancho del sépalo, longitud del pétalo, ancho del pétalo)\n",
    "- Variable de **respuesta** es la especie iris\n",
    "- Es un problema de **clasificación** ya que la respuesta es categórica\n",
    "- Para mayor información sobre el dataset, consultar [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Iris) o [Wikipedia - Conjunto de datos flor iris](https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2. Terminología de Machine learning\n",
    "\n",
    "- Cada fila es una **observación** (tambien conocida como: muestra, ejemplo, caso o registro)\n",
    "- Cada columna es una **característica** (tambien conocido como: predictor, atributo, variable independiente, regresor, o covariable)\n",
    "- Cada valor que predecimos es la **respuesta** (tambien conocida como objetivo, etiqueta, o variable dependiente)\n",
    "- **Clasificación** es aprendizaje supervisado en donde la respuesta es categórica\n",
    "- **Regresión** es aprendizaje supervisado en donde la respuesta es continua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3. Clasificación con Algoritmo K-nearest neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Funcionamiento básico del algoritmo:\n",
    "1. Selecciona un valor para K. Este valor es provisto antes de que se ejecute el algoritmo.\n",
    "2. Realiza una búsqueda de las K observaciones más \"cercanas\" a las mediciones de la flor iris por identificar, en el conjunto de datos de entrenamiento.\n",
    "3. Usa el valor de la respuesta más común entre los K vecinos más cercanos como el valor de respuesta (predicción) para la flor iris por identificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Ejemplo del Conjunto de Datos de Entrenamiento\n",
    "Esta es una gráfica de todos los datos, presentados en un eje de dos dimensiones.\n",
    "\n",
    "![Training data](img/knn_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Mapa de Clasificación KNN (K=1)\n",
    "Si seleccionas un valor de `K=1`, asi quedarían clasificados cada una de las muestras. En los casos en que la clasificación no fue correcta, verás nodos de un color sobre áreas de otros colores. Por ejemplo, hay dos nodos verde encima del zona roja, en la esquina superior izquierda de la gráfica.\n",
    "![1NN classification map](img/1nn_mapa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Mapa de Clasificación KNN (K=5)\n",
    "Al cambiar el valor a `K=5`, el algoritmo puede utilizar más muestras de referencia para determinar la clase de cada uno de las muestras evaluadas. Comparando con le gráfica cuando `K=1`, es mejor o no el resultado? \n",
    "![5NN classification map](img/5nn_mapa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Creditos de Imagenes: [Data3classes](http://commons.wikimedia.org/wiki/File:Data3classes.png#/media/File:Data3classes.png), [Map1NN](http://commons.wikimedia.org/wiki/File:Map1NN.png#/media/File:Map1NN.png), [Map5NN](http://commons.wikimedia.org/wiki/File:Map5NN.png#/media/File:Map5NN.png) by Agor153. Licensed under CC BY-SA 3.0*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Cargando el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# importa la función load_iris del módulo datasets\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# guarda el objeto tipo \"bunch\", que contiene el dataset iris y sus atributos\n",
    "iris = load_iris()\n",
    "\n",
    "# almacena la matriz de características en \"X\"\n",
    "X = iris.data\n",
    "\n",
    "# almacena el vector de respuesta en \"y\"\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# imprime las dimensiones de \"X\" y \"y\"\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Proceso de 4-etapas para crear el modelo en scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Paso 1:** Importa la clase del algoritmo que planeas utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Paso 2:** \"Instancia\" o crea el \"estimador\"\n",
    "\n",
    "- \"Estimador\" es el termino de scikit-learn para modelo\n",
    "- \"Instanciar\" significa \"crear una instancia (objeto) de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- El nombre del objeto no importa, puedes seleccionar el que desees\n",
    "- Puedes especificar también los parametros de entrenamiento (tambien conocidos como \"hiper'parámetros\") durante la creacion de la instancia/objeto\n",
    "- Cualquier parámetro que no sea específico utilizará un valor por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Paso 3:** Ajustar (fit) el modelo a los datos (conocido como el \"entrenamiento del modelo\")\n",
    "\n",
    "- El modelo aprende la relación entre \"X\" y \"y\"\n",
    "- Ocurre \"in-place\" (el modelo se actualiza con los resultados del entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Paso 4:** Predecir la respuesta para una nueva muestra\n",
    "\n",
    "- Las nuevas muestras son aquellos datos no utilizados durante el entrenamiento\n",
    "- Utiliza la información aprendida durante el proceso de entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ¿Qué tipo de iris tiene un sepalo de 3cm x 5cm y un petalo de 4cm x 2cm?\n",
    "# necesitamos utilizar el metodo 'predict()'\n",
    "resultado_1 = knn.predict([[3, 5, 4, 2]])\n",
    "resultado_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# La respuesta retorna un arreglo de tipo \"NumPy\" que contiene la posición de la clase elegida. Si quieres ver que \n",
    "# clase es debes pasar este resultado a la lista de clases.\n",
    "print(iris.target_names[resultado_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# El modelo también puede predecir múltiples muestras a la vez\n",
    "X_new = [[1, 5, 1, 4], [5, 4, 3, 2]]\n",
    "resultado_2 = knn.predict(X_new)\n",
    "print(iris.target_names[resultado_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambien puedes hacer predicciones probabilísticas, usando el metodo 'predict_proba()'. El modelo te retorna\n",
    "# entonces una probabilidad y no la decisión.\n",
    "knn.predict_proba([[3, 5, 4, 2],])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** Como interpretas el resultado de arriba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Usando un valor diferente para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Crea el modelo o estimador (usando el valor K=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# entrena el modelo con el dataset\n",
    "knn.fit(X, y)\n",
    "\n",
    "# predice la clase para las nuevas observaciones\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qué tipo de iris son:\n",
    "# - flor con sepalo de 3cm x 5cm y un petalo de 4cm x 2cm?\n",
    "# - flor con sepalo de 1cm x 5cm y un petalo de 1cm x 4cm?\n",
    "# - flor con sepalo de 5cm x 4cm y un petalo de 3cm x 2cm?\n",
    "# necesitamos utilizar el metodo 'predict()'\n",
    "resultado_3 = knn.predict([[3, 5, 4, 2], [1, 5, 1, 4], [5, 4, 3, 2]])\n",
    "print(iris.target_names[resultado_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Cambian las respuestas entre los modelos cuando `K=1` y `K=5`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo KNN con K=3 y usando nuevo dataset de evaluación\n",
    "Vamos a entrenar un modelo con `K=3`, utilizando sólo dos de las cuatro características del dataset original. Esto lo hacemos para facilitar el gráfico que queremos crear al final.\n",
    "Adicionalmente, creamos un dataset de evaluación de 100 muestras, utilizando la librería `numpy`. Este dataset no es real (tomando medidas de flores), pero si basado en el dataset original (que si es real)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo KNN con K=3\n",
    "X2 = iris.data[:, :2]  # sólo tomamos las dos primeras columnas del dataset\n",
    "y = iris.target\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_3.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion del dataset de 100 muestras para evaluar el modelo entrenado\n",
    "import numpy as np\n",
    "\n",
    "# determinamos el rango de valores (tanto en el eje X como en el eje Y)\n",
    "# de donde se puede crear las nuevas muestras\n",
    "x_min, x_max = X2[:, 0].min() - .1, X2[:, 0].max() + .1\n",
    "y_min, y_max = X2[:, 1].min() - .1, X2[:, 1].max() + .1\n",
    "\n",
    "# creamos el dataset de evaluación con 100 muestras\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "\n",
    "# calculamos las predicciones para las 100 muestras de evaluación\n",
    "Z = knn_3.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos dos clases dentro de la librería matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creamos mapas de colores para un problema de clasificación\n",
    "# de tres clases, como es el dataset iris\n",
    "# los colores elegidos, están definidos en formato hexadecimal\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "# Colocamos el resultado en una gráfica (fondo de la gráfica)\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Graficamos tambien las muestras de entrenamiento\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Ajuste de Parámetro: Como encontrar un valor apropiado de K\n",
    "\n",
    "Cuando usas el algoritmo KNN, encontrar un valor apropiado de `K` no es fácil. Si utilizas un valor muy pequeño de `k`, significa que el ruido en los datos tendrá una mayor influencia sobre los resultados. Si usas un valor muy grande, el algoritmo tomara más tiempo en ejecutarse (computacionalmente costoso).\n",
    "\n",
    "Usualmente los científicos de datos siguen dos recomendaciones:\n",
    "- el valor de `K` debe ser impar para evitar empates\n",
    "- seleccionar $K=\\sqrt{n}$ donde `n` es el número de muestras de entrenamiento\n",
    "\n",
    "Una técnica más estructurada es probar K para múltiples valores y calcular el rendimiento de clasificación para cada uno de los modelos entrenados. Debido a que esto puede ser un cálculo intenso, dependiendo del tamaño del dataset, se recomienda usualmente utilizar un subconjunto de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# importamos las librerias necesarias\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# experimentando con valores entre 1 y 25 para K\n",
    "k_range = list(range(1,26))\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X, y)\n",
    "    y_pred = knn.predict(X)\n",
    "    # calculamos la exactitud (accuracy) de cada modelo\n",
    "    scores.append(metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "# graficamos los resultados\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Valor de k')\n",
    "plt.ylabel('Exactitud en la Respuesta')\n",
    "plt.title('Precision alcanzada para distintos valores de K en K-Nearest-Neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Pregunta:** ¿Cuál es (o son) los valores de K que debemos seleccionar segun la gráfica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Pregunta:** ¿Debemos escoger el valor de K = 1? ¿Qué dice la gráfica? ¿Estás de acuerdo? ¿Por qué sí o no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Pregunta:** ¿Qué valor de K escogerías finalmente, según la gráfica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4. Clasificación con Algoritmo de Árbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copiando (de nuevo) los datos\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# creando un dataframe donde guardaremos los datos de entrenamiento\n",
    "d = [{\"sepal_length\":row[0], \n",
    "      \"sepal_width\":row[1], \n",
    "      \"petal_length\":row[2], \n",
    "      \"petal_width\":row[3]} for row in x]\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "# asignar las clases al dataframe\n",
    "df[\"types\"] = y \n",
    "# cambiar aleatoriamente el orden de las filas\n",
    "df = df.sample(frac=1.0)\n",
    "# mostrar las primeras cinco filas del dataframe, para confirmar\n",
    "# que todo está en orden\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la libreria [Seaborn](https://seaborn.pydata.org/), que está basada en `matplotlib`, para usar un poderoso método que permite fácilmente graficar las relaciones entre los pares de características de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.5)\n",
    "sns.pairplot(df,hue=\"types\",size=3);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Pregunta:** ¿Qué características parecen dividir mejor los datos? ¿Qué características no parecen funcionar muy bien? ¿Qué clases son más difíciles de distinguir entre ellas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# 5. Dividir el conjunto de datos en entrenamiento y evaluación\n",
    "Es importante no entrenar sobre todos los datos, ya que esto puede crear modelos con sobreajustes (overfit). Para evitarlo, los datos pueden dividirse en dos grupos: datos de entrenamiento y datos de evaluación. Estos últimos no son utilizados para entrenar el modelo. En su lugar, son sólo utilizados para determinar cuán bien el modelo entrenado hace las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dividir conjunto de datos en dos grupos: entrenamiento (train) y evaluación (test),\n",
    "# escogiendo 80% (ratio = 0.8) para entrenamiento y el resto para evaluación\n",
    "features = df[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]]\n",
    "types = df[\"types\"]\n",
    "train_features, test_features, train_types, test_types = train_test_split(features,types,train_size=0.8, \n",
    "                                                                          random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamiento del árbol de decisión con el 80% de los datos\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicción sobre el 20% de los datos (evaluación)\n",
    "predicciones = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluación de la clasificación (multi-clase) del modelo\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_types, predicciones, target_names=[\"type0\",\"type1\",\"type2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando la tecnica de validación cruzada con la división de entrenamiento/evaluación\n",
    "\n",
    "Ventajas de la división de **entrenamiento/evaluación:**\n",
    "- Corre K veces más rápido que una validación cruzada K-fold\n",
    "- Más sencillo de examinar los resultados obtenidos del proceso de evaluación\n",
    "\n",
    "Ventajas de **validación cruzada:**\n",
    "- Una estimación más precisa de la exactitud (accuracy) del modelo\n",
    "- Uso más 'eficiente' de los datos (cada observación es usada tanto para entrenamiento como evaluación)\n",
    "\n",
    "## Recomendaciones de Validación Cruzada\n",
    "\n",
    "1. En problemas de clasificación, se recomienda utilizar el **muestreo estratificado** para crear los `folds`\n",
    "   - Cada clase debe ser representada en proporciones similares en cada uno de los `K` folds\n",
    "   - La función `cross_val_score` realiza esta operación por defecto\n",
    "\n",
    "## Ajuste de Parámetro: Como encontrar un valor apropiado de K (usando validacion cruzada)\n",
    "\n",
    "**Meta:** Volvemos a utilizar KNN en el dataset iris para seleccionar los hyper-parámetros, usando la tecnica de validacion cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# validación cruzada 10-fold con K=5 para KNN (parámetro `n_neighbors`)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usa el valor promedio de la exactitud (accuracy) como un estimado del rendimiento `out-of-sample`\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busca el valor óptimo de K para KNN\n",
    "k_range = list(range(1, 31))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# grafica el valor de K para KNN (eje x) contra la exactitud validada (eje y)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Valor de K para KNN')\n",
    "plt.ylabel('Exactitud por Validación Cruzada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Recursos\n",
    "\n",
    "- Kaggle. [Using Scikit-learn to Implement a Simple Decision Tree Classifier](https://www.kaggle.com/chrised209/decision-tree-modeling-of-the-iris-dataset)\n",
    "- [Nearest Neighbors](http://scikit-learn.org/stable/modules/neighbors.html) (user guide), [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (class documentation)\n",
    "- [Videos de Una Introduccion a Aprendizaje Estadistico](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
